#Bonus_Day005_Day006_Day007 - CNN Pokemon dataset
"""Bonus_Day005_Day006_Day007_CNN_Pokemon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AFUXqwekMv8LyEBZ_M2_BYEyMKWEPNEf
"""

#First mount
import os
print(os.getcwd())

#CNN model building
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense

model = Sequential()

#1st layer
model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu')) #Step1 & Step2 - convolution and relu activation function
model.add(MaxPooling2D(pool_size = (2, 2))) #Step3 - MaxPooling

#2nd layer
model.add(Conv2D(32, (3, 3), activation = 'relu')) #Step1 & Step2 - convolution and relu activation function
model.add(MaxPooling2D(pool_size = (2, 2))) #Step3 - MaxPooling

model.add(Flatten()) #Step4 - Flattening

model.add(Dense(units = 128, activation = 'relu')) #64p + 64p = 128p => 128 total input nodes
model.add(Dense(units = 3, activation = 'softmax')) #depth - 3 => output node - 3

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) #compiling CNN with adam optimizer

model.summary() #Summary of our model

#Fitting our CNN model to the images
from keras.preprocessing.image import ImageDataGenerator

train_data_generate = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)

test_data_generate = ImageDataGenerator(rescale = 1./255)

#now we have to add the shortcut to the Drive of our Data folder in My Drive then use below one: importing dataset folders
train_set = train_data_generate.flow_from_directory('E:/Forsk internship - My Learning Outcomes/Bonus Exercises/Bonus_Day005_Day006_Day007_CNN_MNIST_Dataset_Pokemon_dataset/Dataset/training_set', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')

test_set = test_data_generate.flow_from_directory('E:/Forsk internship - My Learning Outcomes/Bonus Exercises/Bonus_Day005_Day006_Day007_CNN_MNIST_Dataset_Pokemon_dataset/Dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')

print(type(train_set))
print(type(train_data_generate))
print(type(test_set))
print(type(test_data_generate))

model.fit_generator(train_set, steps_per_epoch = 10, epochs = 5, validation_data = test_set, validation_steps = 200) #steps per epoch - one batch size will get repeated this much time in one epoch

"""***Using the Pretrained Model: VGG16***


"""

from tensorflow.keras.applications import VGG16

conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (150, 150, 3)) #include_top=False, means ANN part excluded and CNN part included

conv_base.summary()

from keras import models
from keras import layers
import os
model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))

conv_base.trainable = False #do not train the conv-base

base_dir = 'E:/Forsk internship - My Learning Outcomes/Bonus Exercises/Bonus_Day005_Day006_Day007_CNN_MNIST_Dataset_Pokemon_dataset/Dataset/'
train_dir = os.path.join(base_dir, 'training_set')

test_dir = os.path.join(base_dir, 'test_set')

from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255) #rescale factor is feature scalling, convert values in the range of 0-1 before applying any processing

train_generator = train_datagen.flow_from_directory(train_dir, 
                                                    target_size=(150, 150),
                                                    batch_size=20,
                                                    class_mode='categorical')

test_generator = test_datagen.flow_from_directory(test_dir,
                                                  target_size=(150, 150),
                                                  batch_size=20,
                                                  class_mode='categorical')

model.compile(loss='categorical_crossentropy',
              optimizer = optimizers.RMSprop(lr=2e-5),
              metrics=['acc'])

history = model.fit_generator(train_generator, steps_per_epoch=10,
                              epochs=5,
                              validation_data=test_generator,
                              validation_steps=50)

"""***Using the pretrained model: Fine tuning the model***

Another widely used technique for model reuse, complementary to feature extraction, is fine-tuning (see figure 5.19). 
Fine-tuning consists of unfreezing a few of the top layers of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in this case, the fully connected classifier) and these top layers. This is called ***fine-tuning*** because it slightly adjusts the more
abstract representations of the model being reused, in order to make them more relevant for the problem at hand.

Thus the steps for fine-tuning a network are as follows:

1.   Add your custom network on top of an already-trained base network.
2.   Freeze the base network.
3.   Train the part you added.
4.   Unfreeze some layers in the base network.
5.   Jointly train both these layers and the part you added.

You already completed the first three steps when doing feature extraction. Let’s proceed
with step 4: you’ll unfreeze your conv_base and then freeze individual layers
inside it.

*You’ll* fine-tune the last three convolutional layers, which means all layers up to block4_pool should be frozen, and the layers block5_conv1, block5_conv2, and block5_conv3 should be trainable.
"""

conv_base.trainable = True
set_trainable = False
for layer in conv_base.layers:
  if layer.name == 'block5_conv1':
    set_trainable = True
    
  if set_trainable:
    layer.trainable = True
  else:
    layer.trainable = False

model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['acc'])

history = model.fit_generator(
    train_generator,
    steps_per_epoch=10,
    epochs=5,
    validation_data=test_generator,
    validation_steps=50)

"""Here’s what you should take away from the exercises in the past two sections:

1. Convnets are the best type of machine-learning models for computer-vision
tasks. It’s possible to train one from scratch even on a very small dataset, with decent results.

2. On a small dataset, overfitting will be the main issue. Data augmentation is a powerful way to fight overfitting when you’re working with image data.

3. It’s easy to reuse an existing convnet on a new dataset via feature extraction. This is a valuable technique for working with small image datasets.

4. As a complement to feature extraction, you can use fine-tuning, which adapts to a new problem some of the representations previously learned by an existing
model. This pushes performance a bit further.
"""

divmod(23, 5) #returns a tuple => (quotient, remainder)
