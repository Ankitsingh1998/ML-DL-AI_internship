{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day082_Introduction_to_google_colab.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J38Cy4-EvtisFR2LHkUr50egwC_bPku1","authorship_tag":"ABX9TyPY6TUMxXEPJpbJ0CvJB1Rv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Ve4ILZBwuLmP"},"source":["#Day082 - ANN\n","#ipynb - interactive python notebook\n","print(2+8)\n","print(\"Hello World!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gFrfnnQ9ui47"},"source":["# *This is a google colab demo class.*"]},{"cell_type":"code","metadata":{"id":"yWN-2S-Nujfp"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HSWuR4kup7R"},"source":["with open('/gdrive/My Drive/foo.txt', 'w') as f:\n","  f.write('Hello Google Drive!')\n","!cat '/gdrive/My Drive/foo.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mY9TUchyup7T"},"source":["import pandas as pd\n","df = pd.read_csv('Balanced_reviews.csv')\n","\n","df.isnull().any(axis=0)\n","df.dropna(inplace=True)\n","df.shape\n","\n","df = df[df['overall'] != 3]\n","df.shape\n","df['overall'].value_counts()\n","\n","import numpy as np\n","df['positivity'] = np.where(df['overall'] > 3, 1, 0)\n","df.shape\n","\n","df['positivity'].value_counts()\n","\n","features = df['reviewText']\n","labels = df['positivity']\n","\n","from sklearn.model_selection import train_test_split\n","features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.5, random_state=42)\n","\n","#Tf-idf : Term frequency - inverse document frequency\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vect = TfidfVectorizer(min_df=5, max_features=3000).fit(features_train)\n","#min_df means ignore the terms/words that appears less than the set value, by default it is 5. \n","\n","len(vect.vocabulary_) #to get total number of vaocabulary created\n","\n","len(vect.get_feature_names())\n","vect.get_feature_names()[6990:7000]\n","\n","features_train_vectorized = vect.transform(features_train)\n","features_train_vectorized = features_train_vectorized.todense()"],"execution_count":null,"outputs":[]}]}