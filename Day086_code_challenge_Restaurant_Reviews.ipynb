{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day086_code_challenge_Restaurant_Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSMOsX8mbKFO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Forsk coding school code practices/Restaurant_Reviews.tsv'\n",
        "df = pd.read_csv(file_path, delimiter = '\\t', quoting = 3) #tsv file - \\t or tab to read it"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "cPTqKjyallN9",
        "outputId": "f5100d9b-0761-40b8-cfce-f794835a3521"
      },
      "source": [
        "df.columns.to_list()\n",
        "df.shape\n",
        "df.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oczBNJkjluhS"
      },
      "source": [
        "features = df['Review']\n",
        "labels = df['Liked']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-okwzHaSkHbr"
      },
      "source": [
        "#Applying train_test_split on dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxFaffWimOeu",
        "outputId": "7290bc07-8103-4f0b-e4a5-0eb62f8b3159"
      },
      "source": [
        "#Creating \"bag of words model\" with Tfidfvectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer(min_df=5) #min_df --> to add those words which are present in features atleast more than min-df\n",
        "\n",
        "features_train_vectorized = tf.fit_transform(features_train) #fitiing the trained data\n",
        "\n",
        "features_train_vectorized.shape\n",
        "\n",
        "features_train_vectorized = features_train_vectorized.toarray() #converting to numpy array\n",
        "\n",
        "features_train_vectorized.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 291)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuUp2-ieofB0",
        "outputId": "ee76e4dd-2b2c-415c-e11e-83816c5a7f2b"
      },
      "source": [
        "features_train_vectorized[0:2] #1st and 2nd row"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.52933092, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.34200575,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.77642826, 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.71782594, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.37945956, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.44011775, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38344847, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZH-0P6Mox-K"
      },
      "source": [
        "#Training and classificatin using Deep learning model\n",
        "from keras.models import Sequential #Sequential - model\n",
        "from keras.layers.core import Dense, Dropout, Activation #dense - layering/layers\n",
        "from keras.optimizers import adadelta_v2, adam_v2, rmsprop_v2\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txr_NHcMpwHc",
        "outputId": "e0bb8eae-6e83-41c7-c9fb-e56a1091ae56"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(291,))) #nodes - 200, input_shape - input layer/total words in bag of model/vectorized features shape\n",
        "model.add(Activation('relu')) #relu - algorithm\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd layer\n",
        "model.add(Dense(100)) #nodes - 100\n",
        "model.add(Activation('relu')) #relu activation\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd layer\n",
        "model.add(Dense(40)) #nodes - 40\n",
        "model.add(Activation('relu')) #relu activation\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#4th layer\n",
        "model.add(Dense(10)) #nodes - 10\n",
        "model.add(Activation('relu')) #relu activation\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#5th layer/output layer/last layer\n",
        "model.add(Dense(1)) #nodel - 1, for output layer\n",
        "model.add(Activation('sigmoid')) #sigmoid activation in output/binary classification\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam') #adam - optimizer and loss is binary_crossentropy\n",
        "\n",
        "model.fit(features_train_vectorized, labels_train, batch_size = 100, epochs = 20) #fitting the model"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 0.6969\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6924\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6934\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6898\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6870\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6854\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6798\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6780\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6702\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6661\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6339\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6308\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6015\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5787\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5512\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5194\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4308\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4160\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3923\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9c6998790>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzMjXR7Ztlms"
      },
      "source": [
        "#predictions\n",
        "\"\"\"\n",
        "Please use instead:* \"np.argmax(model.predict(x), axis=-1)\",   if your model does multi-class classification   \n",
        "(e.g. if it uses a 'softmax' last-layer activation).* \"(model.predict(x) > 0.5).astype(\"int32\")\",   if your model does binary classification\n",
        "(e.g. if it uses a 'sigmoid' last-layer activation)\n",
        "\"\"\"\n",
        "labels_train_prediction = (model.predict(features_train_vectorized) > 0.5).astype(\"int32\")\n",
        "labels_test_prediction = (model.predict((tf.transform(features_test).toarray()))> 0.5).astype(\"int32\")"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYqM8IIDvzi8",
        "outputId": "3ba37b8c-3deb-456b-c101-11b0926fc31a"
      },
      "source": [
        "print(list(zip(labels_train_prediction[0:5], labels_train[0:5])))\n",
        "print(list(zip(labels_test_prediction[0:5], labels_test[0:5])))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array([0], dtype=int32), 0), (array([1], dtype=int32), 1), (array([0], dtype=int32), 0), (array([0], dtype=int32), 0), (array([1], dtype=int32), 1)]\n",
            "[(array([0], dtype=int32), 1), (array([1], dtype=int32), 1), (array([1], dtype=int32), 1), (array([1], dtype=int32), 1), (array([1], dtype=int32), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btfWbC9jxOBH"
      },
      "source": [
        "#print(len(labels_train))\n",
        "#print(len(labels_train_prediction))\n",
        "#print(len(labels_test))\n",
        "#print(len(labels_test_prediction))"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCKfq-R8wPJW",
        "outputId": "51ade844-c61f-41b4-e042-48073b8d5478"
      },
      "source": [
        "#Accuracy/score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Training score is:', accuracy_score(labels_train, labels_train_prediction)*100,'%')\n",
        "print('Testing score is:', accuracy_score(labels_test, labels_test_prediction)*100,'%')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score is: 94.25 %\n",
            "Testing score is: 76.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWWiia7qy0tE",
        "outputId": "08fb496d-34ea-4a6b-ca8b-ea6ae3b12f08"
      },
      "source": [
        "#Accuracy by confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_train, labels_train_prediction)\n",
        "\n",
        "score_train = (cm[0][0] + cm[1][1])/cm.sum()\n",
        "\n",
        "cm2 = confusion_matrix(labels_test, labels_test_prediction)\n",
        "\n",
        "score_test = (cm2[0][0] + cm2[1][1])/cm2.sum()\n",
        "\n",
        "print('confusion matrix for the training set is:\\n',cm)\n",
        "print('Training Accuracy for the model is:',score_train*100,'%')\n",
        "\n",
        "print('confusion matrix for the testing set is:\\n',cm2)\n",
        "print('Testing Accuracy for the model is:',score_test*100,'%')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix for the training set is:\n",
            " [[401   3]\n",
            " [  1 395]]\n",
            "Training Accuracy for the model is: 99.5 %\n",
            "confusion matrix for the testing set is:\n",
            " [[83 13]\n",
            " [35 69]]\n",
            "Testing Accuracy for the model is: 76.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28C4SUfa0QYq",
        "outputId": "0eb6ea52-fb4d-467f-f761-1ff8b07bf4e9"
      },
      "source": [
        "#Testing for a review data sample\n",
        "data = ['This restaurant has less number of workers which makes customers wait for longer than expected.'] #give data as alist\n",
        "\n",
        "data = tf.transform(data) #sparse matrix type - convert to numpy array - use toarray()/todense()\n",
        "\n",
        "data = data.toarray()\n",
        "\n",
        "prediction = (model.predict(data) > 0.5).astype(\"int32\")\n",
        "\n",
        "print(prediction[0][0]) #wrong prediction is coming, more datasets may be required."
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}